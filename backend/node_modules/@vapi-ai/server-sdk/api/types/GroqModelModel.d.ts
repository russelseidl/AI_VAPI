/**
 * This file was auto-generated by Fern from our API Definition.
 */
/**
 * This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
 */
export declare type GroqModelModel = "llama-3.1-405b-reasoning" | "llama-3.1-70b-versatile" | "llama-3.1-8b-instant" | "mixtral-8x7b-32768" | "llama3-8b-8192" | "llama3-70b-8192" | "llama3-groq-8b-8192-tool-use-preview" | "llama3-groq-70b-8192-tool-use-preview" | "gemma-7b-it" | "gemma2-9b-it";
export declare const GroqModelModel: {
    readonly Llama31405BReasoning: "llama-3.1-405b-reasoning";
    readonly Llama3170BVersatile: "llama-3.1-70b-versatile";
    readonly Llama318BInstant: "llama-3.1-8b-instant";
    readonly Mixtral8X7B32768: "mixtral-8x7b-32768";
    readonly Llama38B8192: "llama3-8b-8192";
    readonly Llama370B8192: "llama3-70b-8192";
    readonly Llama3Groq8B8192ToolUsePreview: "llama3-groq-8b-8192-tool-use-preview";
    readonly Llama3Groq70B8192ToolUsePreview: "llama3-groq-70b-8192-tool-use-preview";
    readonly Gemma7BIt: "gemma-7b-it";
    readonly Gemma29BIt: "gemma2-9b-it";
};
